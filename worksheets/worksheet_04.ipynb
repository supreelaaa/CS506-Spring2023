{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 04\n",
    "\n",
    "Name: Shu Xing \n",
    "UID: U97658230\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Distance & Similarity\n",
    "- Cost Functions\n",
    "- K means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance & Similarity\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "a) In the minkowski distance, describe what the parameters p and d are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d is the number of dimension.   \n",
    "p is a parameter that can make the notation bacome flexible. For example, when p=1, it is manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In your own words describe the difference between the Euclidean distance and the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euclidean distance is a measure of the straight-line distance between two points in a multi-dimensional space.  \n",
    "The Manhattan distance,is the sum of the absolute differences between the coordinates of two points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A = (0, 0) and B = (1, 1). When:\n",
    "\n",
    "- p = 1, d(A, B) = 2\n",
    "- p = 2, d(A, B) = $\\sqrt{2} = 1.41$\n",
    "- p = 3, d(A, B) = $2^{1/3} = 1.26$\n",
    "- p = 4, d(A, B) = $2^{1/4} = 1.19$\n",
    "\n",
    "c) Describe what you think distance would look like when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance will be infinitely close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Is the minkowski distance still a distance function when p < 1? Expain why / why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will not be a distance function. When p<1, the result will violate the triangle inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) when would you use cosine similarity over the euclidan distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When direction matters more than magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) what does the jaccard distance account for that the manhattan distance doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jaccard distance accounts for the size of the intersection and union of the two sets, while the Manhattan distance only accounts for the absolute difference between the elements of the two sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"hello my name is Alice\"  \n",
    "s2 = \"hello my name is Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the union of words from both sentences, we can represent each sentence as a vector. Each element of the vector represents the presence or absence of the word at that index.\n",
    "\n",
    "In this example, the union of words is (\"hello\", \"my\", \"name\", \"is\", \"Alice\", \"Bob\") so we can represent the above sentences as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1]\n",
    "#     hello my name is    Bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bob', 'is', 'name', 'Alice', 'my', 'hello']\n",
      "[0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus = [s1, s2]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)\n",
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new sentence to our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"hi my name is Claude\"\n",
    "corpus.append(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the new union of words used to represent s1, s2, and s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bob', 'is', 'name', 'Alice', 'hi', 'my', 'Claude', 'hello']\n"
     ]
    }
   ],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0,0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1,0]\n",
    "#     hello my name is    Bob\n",
    "v3 = [1,1,1,1,0,0,1]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Represent s1, s2, and s3 as vectors as above, using this new set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 1, 0, 1]\n",
      "[1, 1, 1, 0, 0, 1, 0, 1]\n",
      "[0, 1, 1, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)\n",
    "v2 = [1 if x in s2 else 0 for x in all_words]\n",
    "print(v2)\n",
    "v3 = [1 if x in s3 else 0 for x in all_words]\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that computes the manhattan distance between two vectors. Which pair of vectors are the most similar under that distance function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_dist(x,y):\n",
    "    res=0\n",
    "    for i in range(len(x)):\n",
    "        res+=abs(x[i]-y[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a matrix of all these vectors (row major) and add the following sentences in vector form:\n",
    "\n",
    "- \"hi Alice\"\n",
    "- \"hello Claude\"\n",
    "- \"Bob my name is Claude\"\n",
    "- \"hi Claude my name is Alice\"\n",
    "- \"hello Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1= \"hi Alice\"  \n",
    "s2=\"hello Claude\"\n",
    "s3=\"Bob my name is Claude\"\n",
    "s4=\"hi Claude my name is Alice\"\n",
    "s5=\"hello Bob\"\n",
    "\n",
    "v0=[1,1,0,0,0,0,0,0]\n",
    "v1=[0,0,1,1,0,0,0,0]\n",
    "v2=[0,0,0,1,1,1,1,1]\n",
    "v3=[1,1,0,1,0,1,1,1]\n",
    "v4=[0,0,1,0,1,0,0,0]\n",
    "\n",
    "matrix=[[1,1,0,0,0,0,0,0],\n",
    "[0,0,1,1,0,0,0,0],\n",
    "[0,0,0,1,1,1,1,1],\n",
    "[1,1,0,1,0,1,1,1],\n",
    "[0,0,1,0,1,0,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How many rows and columns does this matrix have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "row=len(matrix)\n",
    "print(row)\n",
    "col=len(matrix[1])\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) When using the Manhattan distance, which two sentences are the most similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "similar=100\n",
    "for i in range(0,3):\n",
    "    for j in range(i+1,4):\n",
    "        similar=min(similar,manhattan_dist(matrix[i],matrix[j]))\n",
    "        if similar==manhattan_dist(matrix[i],matrix[j]):\n",
    "            x=i\n",
    "            y=j\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 0 has {0, 0.5} . 2 has {1.5, 2, 6, 6.5, 7}   \n",
    "2. The new center is 0.25 and 4.6   \n",
    "3. 0.25 has {0, 0.5, 1.5, 2}. 4.6 has {6, 6.5, 7}    \n",
    "4. the new center is 1 and 6.5   \n",
    "5. 1 has {1, 0.5, 1.5, 2}.  6.5 has {6, 6.5, 7}\n",
    "6. the canter is still 1 and 6.5\n",
    "7. so the clusters are {1, 0.5, 1.5, 2} and {6, 6.5, 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within-cluster sum of squared errors:  the sum of the squared distances between each data point and its closest cluster centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is sensitive to the initial centroids chosen. The initial centroids can significantly influence the final solution, and different random initializations can result in different final solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it always converge. But is converges to a local optimum, it is not guaranteed to converge to the global optimum. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
